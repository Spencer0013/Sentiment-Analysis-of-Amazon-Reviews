{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca9a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edca1499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Sentiment Analysis of Amazon Reviews\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba5bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a811ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Sentiment Analysis of Amazon Reviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c75602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: str\n",
    "    data_path: str   \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a92bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimentanalyzer.constants import *\n",
    "from sentimentanalyzer.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Union\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from sentimentanalyzer.utils.common import read_yaml, create_directories  # adjust import as needed\n",
    "from sentimentanalyzer.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4304c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Union[str, Path] = CONFIG_FILE_PATH,\n",
    "        params_filepath: Union[str, Path] = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        print(\">>> CONFIG CONTENTS:\", self.config)         # debug\n",
    "        print(\">>> CONFIG KEYS:\", list(self.config.keys()))\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        print(\">>> PARAMS CONTENTS:\", self.params)         \n",
    "        print(\">>> PARAMS KEYS:\", list(self.params.keys()))  \n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path = config.data_path\n",
    "            )\n",
    "\n",
    "        return data_transformation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564fe994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sentimentanalyzer.logging import logger\n",
    "from sentimentanalyzer.constants import *\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from src.sentimentanalyzer.utils.common import load_saved_labels_and_texts,preprocess_ft_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "621fc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        # Load preprocessed data: expects a dict with 'train' and 'test' keys,\n",
    "        # each is a tuple: (labels_list, texts_list)\n",
    "        self.data = load_saved_labels_and_texts(self.config.data_path)\n",
    "        \n",
    "        if not self.data or \"train\" not in self.data or \"test\" not in self.data:\n",
    "            raise ValueError(\"âŒ Data must contain 'train' and 'test' keys with labels and texts.\")\n",
    "        \n",
    "        train_labels, train_texts = self.data.get(\"train\")\n",
    "        test_labels, test_texts = self.data.get(\"test\")\n",
    "        \n",
    "        print(\"ðŸ“Š Train:\", len(train_labels), train_texts[:2])\n",
    "        print(\"ðŸ“Š Test:\", len(test_labels), test_texts[:2])\n",
    "        \n",
    "        # Normalize texts right away\n",
    "        self.train_texts = self.normalize_texts(train_texts)\n",
    "        self.test_texts = self.normalize_texts(test_texts)\n",
    "        self.train_labels = train_labels\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        # Save normalized data back in fastText format\n",
    "        self.save_to_ft_format(\n",
    "            self.train_labels, self.train_texts, \n",
    "            os.path.join(self.config.root_dir, \"train_ft.txt\")\n",
    "        )\n",
    "        self.save_to_ft_format(\n",
    "            self.test_labels, self.test_texts, \n",
    "            os.path.join(self.config.root_dir, \"test_ft.txt\")\n",
    "        )\n",
    "    \n",
    "    def normalize_texts(self, texts: List[str]) -> List[str]:\n",
    "        NON_ALPHANUM = re.compile(r'[\\W]')\n",
    "        NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
    "        normalized_texts = []\n",
    "        \n",
    "        for text in texts:\n",
    "            lower = text.lower()\n",
    "            no_punctuation = NON_ALPHANUM.sub(' ', lower)\n",
    "            no_non_ascii = NON_ASCII.sub('', no_punctuation)\n",
    "            normalized_texts.append(no_non_ascii.strip())\n",
    "        \n",
    "        return normalized_texts\n",
    "    \n",
    "    def save_to_ft_format(self, labels: List[str], texts: List[str], filepath: str):\n",
    "        assert len(labels) == len(texts), \"âŒ Labels and texts length mismatch\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for label, text in zip(labels, texts):\n",
    "                f.write(f\"__label__{label} {text}\\n\")\n",
    "        \n",
    "        print(f\"ðŸ’¾ Saved: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37401ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-18 01:10:37,527: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      ">>> CONFIG CONTENTS: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/Spencer0013/NLP-Text-Summarizer-Project/raw/refs/heads/main/Dataa.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_preprocessing': {'root_dir': 'artifacts/data_preprocessing', 'ingestion_dir': 'artifacts/data_ingestion', 'output_dir': 'artifacts/data_preprocessing'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_preprocessing'}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'data_path': 'artifacts/data_transformation', 'model_save_path': 'artifacts/model_trainer/sentiment_model'}}\n",
      ">>> CONFIG KEYS: ['artifacts_root', 'data_ingestion', 'data_preprocessing', 'data_transformation', 'model_trainer']\n",
      "[2025-06-18 01:10:37,535: INFO: common: yaml file: params.yaml loaded successfully]\n",
      ">>> PARAMS CONTENTS: {'max_tokens': 11470, 'output_sequence_length': 163, 'input_dim': 11470, 'output_dim': 107, 'batch_size': 256, 'epochs': 10, 'label_col': 'target', 'classes': 2, 'learning_rate': 0.001, 'input_dtype': 'int', 'num_labels': 2, 'max_length': 163, 'random_state': 42, 'dropout_rate': 0.1, 'dense_units': 64, 'bert_preprocess_url': 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', 'bert_encoder_url': 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2'}\n",
      ">>> PARAMS KEYS: ['max_tokens', 'output_sequence_length', 'input_dim', 'output_dim', 'batch_size', 'epochs', 'label_col', 'classes', 'learning_rate', 'input_dtype', 'num_labels', 'max_length', 'random_state', 'dropout_rate', 'dense_units', 'bert_preprocess_url', 'bert_encoder_url']\n",
      "[2025-06-18 01:10:37,537: INFO: common: created directory at: artifacts]\n",
      "[2025-06-18 01:10:37,540: INFO: common: created directory at: artifacts/data_transformation]\n",
      "ðŸ“Š Train: 100 ['Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^', \"The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\"]\n",
      "ðŸ“Š Test: 100 ['Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"', \"One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\"]\n",
      "ðŸ’¾ Saved: artifacts/data_transformation\\train_ft.txt\n",
      "ðŸ’¾ Saved: artifacts/data_transformation\\test_ft.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Error occurred during data transformation.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f049e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef52bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f3a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cd417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ed3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
