{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fc230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94e4655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Sentiment Analysis of Amazon Reviews\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943e0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8545819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Sentiment Analysis of Amazon Reviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464ae147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_save_path: Path\n",
    "    epochs:int\n",
    "    classes:int\n",
    "    learning_rate:float\n",
    "    input_dtype: int\n",
    "    params: any\n",
    "    random_state:int\n",
    "    max_tokens: int\n",
    "    output_sequence_length: int\n",
    "    input_dim: int\n",
    "    output_dim: int\n",
    "    batch_size: int\n",
    "    label_col: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83364c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from sentimentanalyzer.utils.common import read_yaml, create_directories, set_seed# adjust import as needed\n",
    "from sentimentanalyzer.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be590a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG_FILE_PATH = Path(\"config/config.yaml\")\n",
    "PARAMS_FILE_PATH = Path(\"params.yaml\")\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Union[str, Path] = CONFIG_FILE_PATH,\n",
    "        params_filepath: Union[str, Path] = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        print(\">>> CONFIG CONTENTS:\", self.config)\n",
    "        print(\">>> CONFIG KEYS:\", list(self.config.keys()))\n",
    "\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        print(\">>> PARAMS CONTENTS:\", self.params)\n",
    "        print(\">>> PARAMS KEYS:\", list(self.params.keys()))\n",
    "\n",
    "        # Create root directory if exists\n",
    "        if 'artifacts_root' in self.config:\n",
    "            create_directories([self.config.artifacts_root])\n",
    "        else:\n",
    "            raise KeyError(\"Missing 'artifacts_root' in config.yaml\")\n",
    "\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Read the `model_trainer` section of the config and\n",
    "        combine it with training params into a ModelTrainerConfig.\n",
    "        \"\"\"\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        # make sure the model‐trainer folder exists\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_save_path=config.model_save_path,\n",
    "            epochs=self.params.epochs,\n",
    "            classes=self.params.classes,\n",
    "            learning_rate=self.params.learning_rate,\n",
    "            input_dtype=self.params.input_dtype,\n",
    "            params=self.params,\n",
    "            random_state= self.params.random_state,\n",
    "            max_tokens=self.params.max_tokens,\n",
    "            output_sequence_length=self.params.output_sequence_length,\n",
    "            input_dim=self.params.input_dim,\n",
    "            output_dim=self.params.output_dim,\n",
    "            batch_size=self.params.batch_size,\n",
    "            label_col=self.params.label_col\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374f8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D, Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sentimentanalyzer.logging import logger\n",
    "from src.sentimentanalyzer.utils.common import load_saved_labels_and_texts,preprocess_ft_txt,load_fasttext_file\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55628b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: 'ModelTrainerConfig'):\n",
    "        self.config = config\n",
    "        self.params = config\n",
    "        tf.random.set_seed(self.config.random_state)\n",
    "        np.random.seed(self.config.random_state)\n",
    "\n",
    "        train_path = Path(config.data_path) / \"train_ft.txt\"\n",
    "        test_path = Path(config.data_path) / \"test_ft.txt\"\n",
    "\n",
    "        self.train_texts, self.train_labels = load_fasttext_file(train_path)\n",
    "        self.test_texts, self.test_labels = load_fasttext_file(test_path)\n",
    "\n",
    "        self.train_texts, self.val_texts, self.train_labels, self.val_labels = train_test_split(\n",
    "        self.train_texts, self.train_labels, random_state=42, test_size=0.2)\n",
    "\n",
    "        self.train_texts = self.train_texts\n",
    "        self.train_labels = self.train_labels\n",
    "        self.val_texts = self.val_texts\n",
    "        self.val_labels =self. val_labels\n",
    "\n",
    "        self.test_texts = self.test_texts\n",
    "        self.test_labels = self.test_labels\n",
    "\n",
    "\n",
    "        \n",
    "    def train(self):\n",
    "        inputs = tf.keras.Input(\n",
    "            shape=(),    \n",
    "            dtype=tf.string\n",
    "        )\n",
    "\n",
    "        vectorizer = layers.TextVectorization(\n",
    "            max_tokens=self.config.max_tokens,\n",
    "            output_sequence_length=self.config.output_sequence_length,\n",
    "            standardize=\"lower_and_strip_punctuation\",\n",
    "            split=\"whitespace\"\n",
    "        )\n",
    "        vectorizer.adapt(self.train_texts)\n",
    "        x = vectorizer(inputs)\n",
    "        x = layers.Embedding(\n",
    "            input_dim=self.config.max_tokens,\n",
    "            output_dim=self.config.output_dim,\n",
    "            mask_zero=True\n",
    "        )(x)\n",
    "        x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPool1D(3)(x)\n",
    "        x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPool1D(5)(x)\n",
    "        x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "        x = layers.GlobalMaxPool1D()(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(20,activation='relu')(x)\n",
    "        # 4) Classification head — use `classes` from params\n",
    "        outputs = layers.Dense(\n",
    "            units=self.params.classes,\n",
    "            activation=\"softmax\",\n",
    "            name=\"classifier\"\n",
    "        )(x)\n",
    "        model = models.Model(inputs=inputs, outputs=outputs, name=\"EmbeddingConv1DModel\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=self.params.learning_rate),\n",
    "            loss=losses.SparseCategoricalCrossentropy(), \n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        # 7) Train\n",
    "        history = model.fit(\n",
    "            x=np.array(self.train_texts),\n",
    "            y=np.array(self.train_labels),\n",
    "            batch_size=self.config.batch_size,\n",
    "            epochs=self.config.epochs,\n",
    "            validation_data=(\n",
    "                np.array(self.val_texts),\n",
    "                np.array(self.val_labels)\n",
    "            )\n",
    "        )\n",
    "        # 8) Save\n",
    "        model.save(self.config.model_save_path, save_format='tf')\n",
    "        logger.info(f\"Model saved to {self.config.model_save_path}\")\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e61d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-17 21:00:35,204: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      ">>> CONFIG CONTENTS: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/Spencer0013/NLP-Text-Summarizer-Project/raw/refs/heads/main/Dataa.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_preprocessing': {'root_dir': 'artifacts/data_preprocessing', 'ingestion_dir': 'artifacts/data_ingestion', 'output_dir': 'artifacts/data_preprocessing'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_preprocessing'}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'data_path': 'artifacts/data_transformation', 'model_save_path': 'artifacts/model_trainer/sentiment_model'}, 'model_trainer_use': {'root_dir': 'artifacts/model_trainer_USE', 'data_path': 'artifacts/data_preprocessing', 'use_model_path': 'https://tfhub.dev/google/universal-sentence-encoder/4', 'model_save_path': 'artifacts/model_trainer_USE/model.h5'}, 'model_trainer_bert': {'root_dir': 'artifacts/model_trainer_bert', 'save_data_dir': 'artifacts/model_trainer_USE', 'model_save_path': 'artifacts/model_trainer_bert/sentiment_model'}}\n",
      ">>> CONFIG KEYS: ['artifacts_root', 'data_ingestion', 'data_preprocessing', 'data_transformation', 'model_trainer', 'model_trainer_use', 'model_trainer_bert']\n",
      "[2025-06-17 21:00:35,213: INFO: common: yaml file: params.yaml loaded successfully]\n",
      ">>> PARAMS CONTENTS: {'max_tokens': 11470, 'output_sequence_length': 163, 'input_dim': 11470, 'output_dim': 107, 'batch_size': 256, 'epochs': 10, 'label_col': 'target', 'classes': 2, 'learning_rate': 0.001, 'input_dtype': 'int', 'num_labels': 2, 'max_length': 163, 'random_state': 42, 'dropout_rate': 0.1, 'dense_units': 64, 'bert_preprocess_url': 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', 'bert_encoder_url': 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2'}\n",
      ">>> PARAMS KEYS: ['max_tokens', 'output_sequence_length', 'input_dim', 'output_dim', 'batch_size', 'epochs', 'label_col', 'classes', 'learning_rate', 'input_dtype', 'num_labels', 'max_length', 'random_state', 'dropout_rate', 'dense_units', 'bert_preprocess_url', 'bert_encoder_url']\n",
      "[2025-06-17 21:00:35,216: INFO: common: created directory at: artifacts]\n",
      "[2025-06-17 21:00:35,216: INFO: common: created directory at: artifacts]\n",
      "[2025-06-17 21:00:35,221: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Model: \"EmbeddingConv1DModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 163)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 163, 107)          1227290   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 163, 64)           34304     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 163, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 54, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 50, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 6, 64)             20544     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1300      \n",
      "                                                                 \n",
      " classifier (Dense)          (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,304,536\n",
      "Trainable params: 1,304,280\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7475 - accuracy: 0.6125 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4067 - accuracy: 0.7750 - val_loss: 0.6949 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1697 - accuracy: 0.9875 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.4500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.6500\n",
      "[2025-06-17 21:00:40,191: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.]\n",
      "[2025-06-17 21:00:40,921: INFO: builder_impl: Assets written to: artifacts/model_trainer/sentiment_model\\assets]\n",
      "[2025-06-17 21:00:41,049: INFO: 1829422008: Model saved to artifacts/model_trainer/sentiment_model]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49adb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd76890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e778102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c3297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5f8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c6a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd66986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96955f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cba0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc6440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
